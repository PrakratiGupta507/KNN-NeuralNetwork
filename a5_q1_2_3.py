# -*- coding: utf-8 -*-
"""A5_Q1_2_3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yDuzCUp69NcBa7DUcrtqZAvtpfN_7gCI
"""

from google.colab import drive
drive.mount('/content/gdrive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math
import operator 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

train_data = pd.read_csv('/content/gdrive/My Drive/ML_Assignment5/sat.trn',header=None,delimiter=" ")
test_data = pd.read_csv('/content/gdrive/My Drive/ML_Assignment5/sat.tst',header=None,delimiter=" ")

"""Part2

"""

X=train_data.iloc[:,:-1]
X1=test_data.iloc[:,:-1]
y=train_data[36]
y1=test_data[36]

error_rate = []
# Might take some time
for i in range(1,50):
    
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X,y)
    pred_i = knn.predict(X1)
    error_rate.append(np.mean(pred_i != y1))

plt.figure(figsize=(10,6))
plt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', marker='o',
         markerfacecolor='red', markersize=10)
plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')

def euclideanDistance(instance1, instance2, attributes):
    distance = 0.0
    for attribute in range(attributes):
        x = instance1[attribute]-instance2[attribute]
        distance += pow((x), 2)
    return math.sqrt(distance)

def neighboutsSelection(train, test, k, length):
    trainData = train.values
    distanceSet = []
    for index in range(len(train)):
        distance = euclideanDistance(trainData[index], test.values[0], length)
        distanceSet.append([trainData[index], distance])
    distanceSet.sort(key = operator.itemgetter(1))
    neighbours = []
    for index in range(k):
        x = 0
        neighbours.append(distanceSet[index][0])
    return neighbours

def predictLabel(neighbours, labelIndex, uniqueValues):
    labels = {}
    for x in uniqueValues:
        labels[x] = 0
    for index in range(len(neighbours)):
        labels[neighbours[index][labelIndex - 1]] += 1
    sortedLabels = sorted(labels.items(), key = operator.itemgetter(1), reverse = True)
    return sortedLabels[0][0]

def evaluateTestData(train, test, k, length):
    predictData = []
    for index in range(len(test)):
        neighbours = neighboutsSelection(train, test.iloc[[index]], k, length)
        x = 0
        predictData.append([test.iloc[[index]], predictLabel(neighbours, len(train.iloc[0]), uniqueValues)])
    return predictData

def evaluatePredictData(predictData, testLen, uniqueValues):
    correct = 0
    TP, FP, FN = 0, 0, 0
    for data in predictData:
        if str(data[-2][target].values[0]) == str(data[1]):
            correct += 1
            if str(uniqueValues[0]) == str(data[1]):
                TP += 1
            else:
                FP += 1
        elif not str(uniqueValues[0]) == str(data[1]):
            FN += 1
    print("Accuracy : ",correct/testLen)
    X = TP + FN
    Y = TP + FP
    Recall, Precision = 1, 1
    if X:
        Recall = TP/ X
    if Y:
        Precision = TP/ Y
    print("\nRecall is : ", Recall)
    print("\nPrecision is : ", Precision)
    if Precision or Recall:
        print("\nF1 Score is : ", (2 * (Recall * Precision))/ (Recall + Precision))

"""Part 3

"""

#testing accuracy using custom
target=36
k=5
uniqueValues = np.unique(train_data[target]) 
predicted = evaluateTestData(train_data, test_data, k, len(train_data.columns)-1)
evaluatePredictData(predicted, len(test_data), uniqueValues)

#training accuracy using custom
target=36
k=5
uniqueValues = np.unique(train_data[target]) 
predicted = evaluateTestData(train_data, train_data, k, len(train_data.columns)-1)
evaluatePredictData(predicted, len(train_data), uniqueValues)

#testing accuracy using sklearn knn
knn = KNeighborsClassifier(n_neighbors=5) 
knn.fit(X,y)
pred_i = knn.predict(X1)
accuracy_score(y1,pred_i)

#training accuracy using Sklearn KNN
pred=knn.predict(X)
accuracy_score(y,pred)

